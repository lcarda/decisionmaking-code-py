=== EXECUTION STARTED AT 2025-06-20 18:45:24 ===
Log will be saved to: /home/pop/Documents/Carrera/tomacode/decisionmaking-code-py/src/exercises/logs/execution_log_20250620_184524.txt
============================================================
=========================================================
Calculate the Nash Equilibrium for Traveler's Dilemma
Running...

 Running a Nash Equilibrium
   • Penalty: 0
   • Real Value: 3

Agent 0:
   • Estrategy 2: 1.0000 (100.00%)
   • Estrategy 3: -0.0000 (-0.00%)

Agent 1:
   • Estrategy 2: 1.0000 (100.00%)
   • Estrategy 3: -0.0000 (-0.00%)

Complete policies saved in: /home/pop/Documents/Carrera/tomacode/decisionmaking-code-py/src/exercises/datos/nash_equilibrium_game_0_3.json
Time taken: 1.0197863578796387 s


=========================================================


Running a Hierarchical Softmax
   • Penalty: 0
   • Real Value: 3
   • Precision (λ): 1
   • Depths of rationality (k): 0

Results of Hierarchical Softmax:
Agent 1:
   • Strategy 2: 0.5000 (50.00%)
   • Strategy 3: 0.5000 (50.00%)

Agent 2:
   • Strategy 2: 0.5000 (50.00%)
   • Strategy 3: 0.5000 (50.00%)


 ⏱️  Time taken: 0.0002372264862060547

Running a Hierarchical Softmax
   • Penalty: 0
   • Real Value: 3
   • Precision (λ): 1
   • Depths of rationality (k): 2

Results of Hierarchical Softmax:
Agent 1:
   • Strategy 3: 0.6508 (65.08%)
   • Strategy 2: 0.3492 (34.92%)

Agent 2:
   • Strategy 3: 0.6508 (65.08%)
   • Strategy 2: 0.3492 (34.92%)


 ⏱️  Time taken: 0.0005908012390136719

Running a Hierarchical Softmax
   • Penalty: 0
   • Real Value: 3
   • Precision (λ): 0.2
   • Depths of rationality (k): 0

Results of Hierarchical Softmax:
Agent 1:
   • Strategy 2: 0.5000 (50.00%)
   • Strategy 3: 0.5000 (50.00%)

Agent 2:
   • Strategy 2: 0.5000 (50.00%)
   • Strategy 3: 0.5000 (50.00%)


 ⏱️  Time taken: 0.00018739700317382812

Running a Hierarchical Softmax
   • Penalty: 0
   • Real Value: 3
   • Precision (λ): 0.2
   • Depths of rationality (k): 2

Results of Hierarchical Softmax:
Agent 1:
   • Strategy 3: 0.5262 (52.62%)
   • Strategy 2: 0.4738 (47.38%)

Agent 2:
   • Strategy 3: 0.5262 (52.62%)
   • Strategy 2: 0.4738 (47.38%)


 ⏱️  Time taken: 0.0030770301818847656

All Hierarchical Softmax results saved in: /home/pop/Documents/Carrera/tomacode/decisionmaking-code-py/src/exercises/datos/hierarchical_softmax_game_0_3.json
=========================================================

=========================================================
Calculate the Nash Equilibrium for Traveler's Dilemma
Running...

 Running a Nash Equilibrium
   • Penalty: 1
   • Real Value: 3

Agent 0:
   • Estrategy 3: 1.0000 (100.00%)
   • Estrategy 2: -0.0000 (-0.00%)

Agent 1:
   • Estrategy 3: 1.0000 (100.00%)
   • Estrategy 2: -0.0000 (-0.00%)

Complete policies saved in: /home/pop/Documents/Carrera/tomacode/decisionmaking-code-py/src/exercises/datos/nash_equilibrium_game_1_3.json
Time taken: 0.019916772842407227 s


=========================================================


Running a Hierarchical Softmax
   • Penalty: 1
   • Real Value: 3
   • Precision (λ): 1
   • Depths of rationality (k): 0

Results of Hierarchical Softmax:
Agent 1:
   • Strategy 2: 0.5000 (50.00%)
   • Strategy 3: 0.5000 (50.00%)

Agent 2:
   • Strategy 2: 0.5000 (50.00%)
   • Strategy 3: 0.5000 (50.00%)


 ⏱️  Time taken: 0.0003428459167480469

Running a Hierarchical Softmax
   • Penalty: 1
   • Real Value: 3
   • Precision (λ): 1
   • Depths of rationality (k): 2

Results of Hierarchical Softmax:
Agent 1:
   • Strategy 2: 0.6508 (65.08%)
   • Strategy 3: 0.3492 (34.92%)

Agent 2:
   • Strategy 2: 0.6508 (65.08%)
   • Strategy 3: 0.3492 (34.92%)


 ⏱️  Time taken: 0.0007882118225097656

Running a Hierarchical Softmax
   • Penalty: 1
   • Real Value: 3
   • Precision (λ): 0.2
   • Depths of rationality (k): 0

Results of Hierarchical Softmax:
Agent 1:
   • Strategy 2: 0.5000 (50.00%)
   • Strategy 3: 0.5000 (50.00%)

Agent 2:
   • Strategy 2: 0.5000 (50.00%)
   • Strategy 3: 0.5000 (50.00%)


 ⏱️  Time taken: 0.0002493858337402344

Running a Hierarchical Softmax
   • Penalty: 1
   • Real Value: 3
   • Precision (λ): 0.2
   • Depths of rationality (k): 2

Results of Hierarchical Softmax:
Agent 1:
   • Strategy 2: 0.5262 (52.62%)
   • Strategy 3: 0.4738 (47.38%)

Agent 2:
   • Strategy 2: 0.5262 (52.62%)
   • Strategy 3: 0.4738 (47.38%)


 ⏱️  Time taken: 0.0007414817810058594

All Hierarchical Softmax results saved in: /home/pop/Documents/Carrera/tomacode/decisionmaking-code-py/src/exercises/datos/hierarchical_softmax_game_1_3.json
=========================================================

=========================================================
Calculate the Nash Equilibrium for Traveler's Dilemma
Running...

 Running a Nash Equilibrium
   • Penalty: 0
   • Real Value: 5

Agent 0:
   • Estrategy 2: 1.0000 (100.00%)
   • Estrategy 3: -0.0000 (-0.00%)
   • Estrategy 4: -0.0000 (-0.00%)
   • Estrategy 5: -0.0000 (-0.00%)

Agent 1:
   • Estrategy 2: 1.0000 (100.00%)
   • Estrategy 3: -0.0000 (-0.00%)
   • Estrategy 4: -0.0000 (-0.00%)
   • Estrategy 5: -0.0000 (-0.00%)

Complete policies saved in: /home/pop/Documents/Carrera/tomacode/decisionmaking-code-py/src/exercises/datos/nash_equilibrium_game_0_5.json
Time taken: 0.04516863822937012 s


=========================================================


Running a Hierarchical Softmax
   • Penalty: 0
   • Real Value: 5
   • Precision (λ): 1
   • Depths of rationality (k): 0

Results of Hierarchical Softmax:
Agent 1:
   • Strategy 2: 0.2500 (25.00%)
   • Strategy 3: 0.2500 (25.00%)
   • Strategy 4: 0.2500 (25.00%)
   • Strategy 5: 0.2500 (25.00%)

Agent 2:
   • Strategy 2: 0.2500 (25.00%)
   • Strategy 3: 0.2500 (25.00%)
   • Strategy 4: 0.2500 (25.00%)
   • Strategy 5: 0.2500 (25.00%)


 ⏱️  Time taken: 0.0003821849822998047

Running a Hierarchical Softmax
   • Penalty: 0
   • Real Value: 5
   • Precision (λ): 1
   • Depths of rationality (k): 2

Results of Hierarchical Softmax:
Agent 1:
   • Strategy 5: 0.4709 (47.09%)
   • Strategy 4: 0.3143 (31.43%)
   • Strategy 3: 0.1532 (15.32%)
   • Strategy 2: 0.0617 (6.17%)

Agent 2:
   • Strategy 5: 0.4709 (47.09%)
   • Strategy 4: 0.3143 (31.43%)
   • Strategy 3: 0.1532 (15.32%)
   • Strategy 2: 0.0617 (6.17%)


 ⏱️  Time taken: 0.0023522377014160156

Running a Hierarchical Softmax
   • Penalty: 0
   • Real Value: 5
   • Precision (λ): 0.2
   • Depths of rationality (k): 0

Results of Hierarchical Softmax:
Agent 1:
   • Strategy 2: 0.2500 (25.00%)
   • Strategy 3: 0.2500 (25.00%)
   • Strategy 4: 0.2500 (25.00%)
   • Strategy 5: 0.2500 (25.00%)

Agent 2:
   • Strategy 2: 0.2500 (25.00%)
   • Strategy 3: 0.2500 (25.00%)
   • Strategy 4: 0.2500 (25.00%)
   • Strategy 5: 0.2500 (25.00%)


 ⏱️  Time taken: 0.0003266334533691406

Running a Hierarchical Softmax
   • Penalty: 0
   • Real Value: 5
   • Precision (λ): 0.2
   • Depths of rationality (k): 2

Results of Hierarchical Softmax:
Agent 1:
   • Strategy 5: 0.2845 (28.45%)
   • Strategy 4: 0.2689 (26.89%)
   • Strategy 3: 0.2409 (24.09%)
   • Strategy 2: 0.2057 (20.57%)

Agent 2:
   • Strategy 5: 0.2845 (28.45%)
   • Strategy 4: 0.2689 (26.89%)
   • Strategy 3: 0.2409 (24.09%)
   • Strategy 2: 0.2057 (20.57%)


 ⏱️  Time taken: 0.002324819564819336

All Hierarchical Softmax results saved in: /home/pop/Documents/Carrera/tomacode/decisionmaking-code-py/src/exercises/datos/hierarchical_softmax_game_0_5.json
=========================================================

=========================================================
Calculate the Nash Equilibrium for Traveler's Dilemma
Running...

 Running a Nash Equilibrium
   • Penalty: 1
   • Real Value: 5

Agent 0:
   • Estrategy 3: 0.3333 (33.33%)
   • Estrategy 2: 0.3333 (33.33%)
   • Estrategy 5: 0.3333 (33.33%)
   • Estrategy 4: 0.0000 (0.00%)

Agent 1:
   • Estrategy 3: 0.3333 (33.33%)
   • Estrategy 2: 0.3333 (33.33%)
   • Estrategy 5: 0.3333 (33.33%)
   • Estrategy 4: 0.0000 (0.00%)

Complete policies saved in: /home/pop/Documents/Carrera/tomacode/decisionmaking-code-py/src/exercises/datos/nash_equilibrium_game_1_5.json
Time taken: 0.04389047622680664 s


=========================================================


Running a Hierarchical Softmax
   • Penalty: 1
   • Real Value: 5
   • Precision (λ): 1
   • Depths of rationality (k): 0

Results of Hierarchical Softmax:
Agent 1:
   • Strategy 2: 0.2500 (25.00%)
   • Strategy 3: 0.2500 (25.00%)
   • Strategy 4: 0.2500 (25.00%)
   • Strategy 5: 0.2500 (25.00%)

Agent 2:
   • Strategy 2: 0.2500 (25.00%)
   • Strategy 3: 0.2500 (25.00%)
   • Strategy 4: 0.2500 (25.00%)
   • Strategy 5: 0.2500 (25.00%)


 ⏱️  Time taken: 0.00040435791015625

Running a Hierarchical Softmax
   • Penalty: 1
   • Real Value: 5
   • Precision (λ): 1
   • Depths of rationality (k): 2

Results of Hierarchical Softmax:
Agent 1:
   • Strategy 3: 0.2938 (29.38%)
   • Strategy 4: 0.2761 (27.61%)
   • Strategy 2: 0.2218 (22.18%)
   • Strategy 5: 0.2084 (20.84%)

Agent 2:
   • Strategy 3: 0.2938 (29.38%)
   • Strategy 4: 0.2761 (27.61%)
   • Strategy 2: 0.2218 (22.18%)
   • Strategy 5: 0.2084 (20.84%)


 ⏱️  Time taken: 0.0032930374145507812

Running a Hierarchical Softmax
   • Penalty: 1
   • Real Value: 5
   • Precision (λ): 0.2
   • Depths of rationality (k): 0

Results of Hierarchical Softmax:
Agent 1:
   • Strategy 2: 0.2500 (25.00%)
   • Strategy 3: 0.2500 (25.00%)
   • Strategy 4: 0.2500 (25.00%)
   • Strategy 5: 0.2500 (25.00%)

Agent 2:
   • Strategy 2: 0.2500 (25.00%)
   • Strategy 3: 0.2500 (25.00%)
   • Strategy 4: 0.2500 (25.00%)
   • Strategy 5: 0.2500 (25.00%)


 ⏱️  Time taken: 0.00040221214294433594

Running a Hierarchical Softmax
   • Penalty: 1
   • Real Value: 5
   • Precision (λ): 0.2
   • Depths of rationality (k): 2

Results of Hierarchical Softmax:
Agent 1:
   • Strategy 3: 0.2567 (25.67%)
   • Strategy 4: 0.2561 (25.61%)
   • Strategy 2: 0.2439 (24.39%)
   • Strategy 5: 0.2433 (24.33%)

Agent 2:
   • Strategy 3: 0.2567 (25.67%)
   • Strategy 4: 0.2561 (25.61%)
   • Strategy 2: 0.2439 (24.39%)
   • Strategy 5: 0.2433 (24.33%)


 ⏱️  Time taken: 0.003268718719482422

All Hierarchical Softmax results saved in: /home/pop/Documents/Carrera/tomacode/decisionmaking-code-py/src/exercises/datos/hierarchical_softmax_game_1_5.json
=========================================================

Total time taken: 1.1509320735931396 s
============================================================
=== EXECUTION FINISHED AT 2025-06-20 18:45:25 ===
